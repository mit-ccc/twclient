<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Getting data from the Twitter API &mdash; twclient 0.2.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Working with fetched data" href="export.html" />
    <link rel="prev" title="License" href="../overview/license.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> twclient
          </a>
              <div class="version">
                0.2.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview/readme.html">README</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/license.html#apache-license">Apache License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vignettes:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Getting data from the Twitter API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#database-setup">Database setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#api-setup">API setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#actually-pulling-data">Actually pulling data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#a-word-about-identifiers">A word about identifiers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hydrating-users">Hydrating users</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tagging-users">Tagging users</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fetching-tweets">Fetching tweets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fetching-the-follow-graph">Fetching the follow graph</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="export.html">Working with fetched data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apidocs.html">API Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">twclient</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Getting data from the Twitter API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/vignettes/fetch.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="getting-data-from-the-twitter-api">
<h1>Getting data from the Twitter API<a class="headerlink" href="#getting-data-from-the-twitter-api" title="Permalink to this heading"></a></h1>
<p>So you want to analyze some Twitter data. (That’s why you’re here, right?) This
vignette walks through how to get set up and how to acquire the data.</p>
<p><strong>Obligatory disclaimer / reminder</strong>: You should comply with Twitter’s terms of
service and respect user privacy. It’s important to only access data you have a
right to access.</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>Twclient makes acquiring data easier than directly interacting with the Twitter
REST API, which you can do through a lightweight client like Twitter’s own
<a class="reference external" href="https://github.com/twitter/twurl">twurl</a> or a more featureful package like
<a class="reference external" href="https://www.tweepy.org/">tweepy</a>. Using either of these makes you do quite
a bit of work you’d rather avoid: thinking about cursoring and pagination of
results, manually handling multiple sets of credentials if you have more than
one, and of course munging data into the format you want. (No disrespect to
tweepy, of course: twclient uses it for low-level interactions with the Twitter
API.)</p>
<p>Data munging in particular is not a simple task. You may have to keep and
organize the raw json responses from Twitter’s API, and then extract things
from them via a tool like <a class="reference external" href="https://stedolan.github.io/jq/">jq</a>; if using
tweepy, you have to write some python code to serialize the User, Tweet, etc,
objects it produces to a format you can work with.</p>
<p>In general, of course, there’s no way around this: if you want to write an
application like a Twitter client, which people can use to view their feeds,
post tweets, and whatever else, you need the API in its full complexity. But
here we have a simpler task—read-only scraping of data—and so we can make a
simpler tool. (For formatting that data and exporting it from the database,
see the <a class="reference internal" href="export.html"><span class="doc">other vignette on exporting data</span></a>.)</p>
<p>Note that Twitter has other data sources than the REST API, in particular the
<a class="reference external" href="https://developer.twitter.com/en/docs/twitter-api/enterprise/historical-powertrack-api/overview">PowerTrack</a>
API, and this package does not support those. It also does not (yet) support
Twitter’s new <cite>v2 API &lt;https://developer.twitter.com/en/docs/twitter-api&gt;</cite>.</p>
<p>Enough talk! How do you get started?</p>
<p>In brief: This package provides a command-line interface for loading data from
the Twitter REST API into the database of your choice. You can invoke it as
either <code class="docutils literal notranslate"><span class="pre">twitter</span></code>, as in <code class="docutils literal notranslate"><span class="pre">twitter</span> <span class="pre">fetch</span> <span class="pre">users</span> <span class="pre">-n</span> <span class="pre">wwbrannon</span></code> or <code class="docutils literal notranslate"><span class="pre">twclient</span></code>,
as in <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span> <span class="pre">users</span> <span class="pre">-n</span> <span class="pre">wwbrannon</span></code>. (We’ll use the <code class="docutils literal notranslate"><span class="pre">twclient</span></code> alias
in this vignette.) You need to set up the database, get API credentials, and
then pull some data.</p>
</div>
<div class="section" id="database-setup">
<h2>Database setup<a class="headerlink" href="#database-setup" title="Permalink to this heading"></a></h2>
<p>The first step is to set up a database backend. You can use any DB that
<a class="reference external" href="https://docs.sqlalchemy.org/en/14/dialects/">sqlalchemy supports</a>, which
with plugins is quite a few to choose from. This is less intimidating than it
may sound—in fact it’s positively easy. Two good choices are <a class="reference external" href="https://www.postgresql.org/">Postgres</a>, which we’ve used for the SQL examples in the
<a class="reference internal" href="export.html"><span class="doc">data export vignette</span></a>, and the extremely lightweight
<a class="reference external" href="https://www.sqlite.org/index.html">SQLite</a>. Note that while you can use any
database engine with sqlalchemy support, twclient has been tested only with
Postgres and to a lesser degree SQLite.</p>
<p>If you want to use one of these, which DB should you choose? If, like me,
you’re on a Mac, <a class="reference external" href="https://postgresapp.com/">Postgres.app</a> is an excellent
and user-friendly distribution of Postgres. It’s not the only one: among others
you can download the database from [its website](<a class="reference external" href="https://www.postgresql.org/">https://www.postgresql.org/</a>),
use [Amazon RDS](<a class="reference external" href="https://aws.amazon.com/rds/">https://aws.amazon.com/rds/</a>), or [run it with
Docker](<a class="reference external" href="https://hub.docker.com/_/postgres">https://hub.docker.com/_/postgres</a>). SQLite has the advantage of being
built into Python, so that you don’t need to install anything to get started.
(Literally: you can just specify a <a class="reference external" href="https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls">sqlalchemy connection URL</a>, as
discussed below, for a file-backed SQLite database). But Python doesn’t package
a shell or client that lets you interact with SQLite without writing Python
code; if you use SQLite, you may want to install a command-line shell or other
client via a package manager like <a class="reference external" href="https://brew.sh/">Homebrew</a> (on a Mac) or
apt-get (on Debian-based Linux). You can also download such a client from the
<a class="reference external" href="https://www.sqlite.org/index.html">SQLite website</a>. Other DBMSs, like MySQL
or Oracle, may also work but, again, have not been tested.</p>
<p>We’ll use Postgres for the rest of this vignette.</p>
<p>Having set up our database system, we need to do two more things to make it
usable: tell twclient how to use it, and install the data model. First, we’ll
use a <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">config</span></code> subcommand to set up the database:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient config add-db -u <span class="s2">&quot;postgresql:///&quot;</span> postgres
</pre></div>
</div>
<p>This command tells twclient to create a persistent profile for a database and
call it “postgres”, with the database itself identified by a <a class="reference external" href="https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls">sqlalchemy
connection URL</a>. The
specific URL we have here, <code class="docutils literal notranslate"><span class="pre">postgresql:///</span></code>, indicates the default database
on a Postgres DBMS accessed through the default local Unix socket, with
trust/passwordless authentication, using sqlalchemy’s default Postgres driver.
(If, like me, you’re using Postgres.app on a Mac, this is likely the URL you
want to use.) The database profile is stored in a twclient configuration file,
by default <code class="docutils literal notranslate"><span class="pre">~/.twclientrc</span></code>, so that you won’t need to continually provide the
database URL for each command.</p>
<p>Next up, we have to install the data model: create the tables, columns, keys
and other DB objects the twclient package uses. Be aware that doing this will
<strong>drop all existing twclient data in your database</strong>. The <code class="docutils literal notranslate"><span class="pre">twclient</span>
<span class="pre">initialize</span></code> command will do the trick, but to confirm that you understand
running it will <strong>drop all existing twclient data in your database</strong> you have
to specify the <code class="docutils literal notranslate"><span class="pre">-y</span></code> flag:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient initialize -y
</pre></div>
</div>
<p>And that’s it! If you fire up a database client (psql in the case of this
example), you’ll see a new database schema installed. The tables, columns and
other objects are documented, in the form of their sqlalchemy model classes, in
the API documentation for twclient.models.</p>
</div>
<div class="section" id="api-setup">
<h2>API setup<a class="headerlink" href="#api-setup" title="Permalink to this heading"></a></h2>
<p>You can’t get data from the Twitter API without API credentials, so the next
step is to get at least one set of credentials. If you don’t already have
credentials, Twitter has <a class="reference external" href="https://developer.twitter.com/en/docs/twitter-api/getting-started/getting-access-to-the-twitter-api">documentation</a>
on how to get them.</p>
<p>You’ll generally receive four pieces of <a class="reference external" href="https://en.wikipedia.org/wiki/OAuth">OAuth</a> authentication information: a consumer
key, consumer secret, access token and access token secret. If using <a class="reference external" href="https://oauth.net/2/bearer-tokens/">OAuth 2.0
bearer tokens</a> you may receive only a
consumer key and consumer secret. Regardless, you can add them to twclient as
follows (replacing the “XXXXX” with your values, and omitting token and token
secret if using a bearer token):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient config add-api -n twitter1 <span class="se">\</span>
    --consumer-key XXXXX <span class="se">\</span>
    --consumer-secret XXXXX <span class="se">\</span>
    --token XXXXX <span class="se">\</span>
    --token-secret XXXXX
</pre></div>
</div>
<p>Similarly to the database setup, this command stores the credentials in your
config file under an API profile named “twitter1” for ease of use. We’ve only
added one set of credentials here, but you can add arbitrarily many under
different names. Twclient will seamlessly switch between them as each one hits
rate limits.</p>
</div>
<div class="section" id="actually-pulling-data">
<h2>Actually pulling data<a class="headerlink" href="#actually-pulling-data" title="Permalink to this heading"></a></h2>
<p>Now comes the fun part: actually downloading some data. We’ll assume you’ve
pulled together sets of Twitter users and <a class="reference external" href="https://help.twitter.com/en/using-twitter/twitter-lists">Twitter lists</a> you want to
retrieve information on. This example will use the following two files, one
each of individual users and lists of users.</p>
<p>Here’s <code class="docutils literal notranslate"><span class="pre">users.csv</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">screen_name</span>
<span class="n">user1</span>
<span class="n">user2</span>
<span class="n">user3</span>
<span class="n">test1234</span>
<span class="n">foobar</span>
<span class="n">stuff</span>
</pre></div>
</div>
<p>And here’s <code class="docutils literal notranslate"><span class="pre">lists.csv</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span>
<span class="n">cspan</span><span class="o">/</span><span class="n">members</span><span class="o">-</span><span class="n">of</span><span class="o">-</span><span class="n">congress</span>
<span class="mi">23965249864</span>
<span class="mi">182359253</span>
<span class="n">nytimes</span><span class="o">/</span><span class="n">nyt</span><span class="o">-</span><span class="n">journalists</span>
<span class="mi">14624234</span>
<span class="mi">185239864</span>
<span class="mi">172409353</span>
</pre></div>
</div>
<div class="section" id="a-word-about-identifiers">
<h3>A word about identifiers<a class="headerlink" href="#a-word-about-identifiers" title="Permalink to this heading"></a></h3>
<p>In general, Twitter allows you to refer to a user or list by either a) a
numeric user ID or list ID, or b) a human-readable name. Readable names for
users are called screen names, and for lists are called “full names.” List full
names consist of the screen name of the user who owns the list and a
list-specific slug, separated by a slash. (For example,
“cspan/members-of-congress”.)</p>
<p>With twclient, you can mix numeric and human-readable names for lists, as in
<code class="docutils literal notranslate"><span class="pre">lists.csv</span></code> above, but not for users. That is, you could instead use this
<code class="docutils literal notranslate"><span class="pre">users_alternative.csv</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">user_id</span>
<span class="mi">39702507914</span>
<span class="mi">28723520928</span>
<span class="mi">1825471204</span>
<span class="mi">1853209475</span>
<span class="mi">4382530952834</span>
<span class="mi">1725438692309</span>
</pre></div>
</div>
<p>but not one file which mixes user IDs and screen names together. This is
because of the way the underlying Twitter API endpoints are implemented:
They’ll accept mixed references to lists, but not to users.</p>
</div>
<div class="section" id="hydrating-users">
<h3>Hydrating users<a class="headerlink" href="#hydrating-users" title="Permalink to this heading"></a></h3>
<p>The first step is to <a class="reference external" href="https://stackoverflow.com/questions/34191022/what-does-hydrate-mean-on-twitter/34192633">hydrate</a>
the target users, which confirms with the Twitter API that they exist,
retrieves some summary information about them and creates records for them in
the database. You can do this with the <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span></code> family of commands,
and specifically <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span> <span class="pre">users</span></code>. We’ll start by fetching the users in
the lists of <code class="docutils literal notranslate"><span class="pre">lists.csv</span></code>, though you could do the individual users first:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tail -n +2 lists.csv <span class="p">|</span> xargs twclient fetch users -v -b -l
</pre></div>
</div>
<p>This command skips the CSV header line (via <code class="docutils literal notranslate"><span class="pre">tail</span> <span class="pre">-n</span> <span class="pre">+2</span> <span class="pre">lists.csv</span></code>), which
twclient doesn’t actually use, and pipes the rest of it to <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span> <span class="pre">-v</span>
<span class="pre">users</span> <span class="pre">-b</span> <span class="pre">-l</span></code> via <code class="docutils literal notranslate"><span class="pre">xargs</span></code>. The <code class="docutils literal notranslate"><span class="pre">-v</span></code> flag requests verbose output, <code class="docutils literal notranslate"><span class="pre">-b</span></code>
says to continue even if the Twitter API says some of the lists requested are
protected or don’t exist, and <code class="docutils literal notranslate"><span class="pre">-l</span></code> says that the users to hydrate are given
in the form of Twitter lists. (If you’d left the header line out of the CSV
file and wanted to avoid using xargs, note that you could instead write
something like <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span> <span class="pre">users</span> <span class="pre">-v</span> <span class="pre">-b</span> <span class="pre">-l</span> <span class="pre">$(cat</span> <span class="pre">lists.csv)</span></code>.)</p>
<p>Similarly, you can hydrate the individual users as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tail -n +2 users.csv <span class="p">|</span> xargs twclient fetch users -v -b -n
</pre></div>
</div>
<p>A noteworthy difference from the case of lists is that you use the <code class="docutils literal notranslate"><span class="pre">-n</span></code>
option, for users identified by screen names, rather than the <code class="docutils literal notranslate"><span class="pre">-l</span></code> option for
lists.</p>
</div>
<div class="section" id="tagging-users">
<h3>Tagging users<a class="headerlink" href="#tagging-users" title="Permalink to this heading"></a></h3>
<p>Having fetched the users, we may want to give them <em>tags</em> for easier reference
in SQL or later commands. Twclient has a tag table that allows you to associate
arbitrary tag names with user IDs, to keep track of relevant groups of users in
your analysis. Let’s say we want to track all individually fetched users
together, and all users retrieved from lists together, as two groups.</p>
<p>First, we need to create a tag:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient tag create twitter_lists
</pre></div>
</div>
<p>Next, we associate the new tag with the users it should apply to:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tail -n +2 lists.csv <span class="p">|</span> xargs twclient tag apply twitter_lists -l
</pre></div>
</div>
<p>Similarly, we can tag the individually fetched users:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient tag create twitter_users
tail -n +2 users.csv <span class="p">|</span> xargs twclient tag apply twitter_users -l
</pre></div>
</div>
<p>Users fetched from Twitter lists will be associated with the lists they are
members of in the <code class="docutils literal notranslate"><span class="pre">list</span></code> and <code class="docutils literal notranslate"><span class="pre">user_list</span></code> tables, so there’s no need to tag
lists individually.</p>
<p>Finally, we might want to create one tag referring to both sets of users (for
example, to run a regular job for fetching everyone’s tweets). We do the same
two-step as above:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient tag create universe
twclient tag apply universe -g twitter_users twitter_lists
</pre></div>
</div>
<p>This time, however, you can see that the <code class="docutils literal notranslate"><span class="pre">-g</span></code> option allows selecting users
to operate on—whether that’s tagging, hydrating, or fetching tweets and
follow edges—according to tags you’ve defined.</p>
</div>
<div class="section" id="fetching-tweets">
<h3>Fetching tweets<a class="headerlink" href="#fetching-tweets" title="Permalink to this heading"></a></h3>
<p>Now, with fully hydrated users, it’s time to get down to one of our primary
jobs: fetching the users’ tweets. We can do this with the <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span>
<span class="pre">tweets</span></code> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient fetch tweets -v -b -g universe
</pre></div>
</div>
<p>As before, <code class="docutils literal notranslate"><span class="pre">-v</span></code> asks for verbose output, <code class="docutils literal notranslate"><span class="pre">-b</span></code> says to ignore nonexistent or
protected users rather than aborting the job, and <code class="docutils literal notranslate"><span class="pre">-g</span> <span class="pre">universe</span></code> says to fetch
tweets for those users tagged <code class="docutils literal notranslate"><span class="pre">universe</span></code>.</p>
<p>Note that twclient also extensively normalizes the tweet objects returned by
Twitter. In addition to the tweet text, we pull out urls, hashtags, “cashtags”,
user mentions and other things so that it’s easy to compute derived datasets
like the mention / quote / etc graphs over users. (For how to do this and
sample SQL, see the vignette on <a class="reference internal" href="export.html"><span class="doc">exporting data</span></a>.) The
raw json API responses are also saved so that you can work with data we don’t
parse.</p>
</div>
<div class="section" id="fetching-the-follow-graph">
<h3>Fetching the follow graph<a class="headerlink" href="#fetching-the-follow-graph" title="Permalink to this heading"></a></h3>
<p>Finally, we want to get the user IDs of our target users’ followers and
friends. (A “friend” is Twitter’s term for the opposite of a follower: if A
follows B, B is A’s friend and A is B’s follower.) There are two more
<code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span></code> subcommands for this: <code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span> <span class="pre">friends</span></code> and
<code class="docutils literal notranslate"><span class="pre">twclient</span> <span class="pre">fetch</span> <span class="pre">followers</span></code>. Neither command hydrates users, because the
underlying Twitter API endpoints don’t, so the <code class="docutils literal notranslate"><span class="pre">follow</span></code> table will end up
being populated with bare numeric user IDs.</p>
<p>Here’s fetching friends, using options you’ve seen all of by now:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient fetch friends -v -b -g universe
</pre></div>
</div>
<p>And here’s followers:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>twclient fetch followers -v -b -p -j <span class="m">5000</span> -g universe
</pre></div>
</div>
<p>The one new flag used here, <code class="docutils literal notranslate"><span class="pre">-j</span> <span class="pre">5000</span></code>, indicates the size of the batch used
for loading follow edges. The default if you don’t use <code class="docutils literal notranslate"><span class="pre">-j</span></code> is to accumulate
all edges in memory and load them at once, which is faster but can cause
out-of-memory errors for large accounts. Specifying <code class="docutils literal notranslate"><span class="pre">-j</span></code> will trade runtime
for memory and let you process these large accounts.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">-v</span></code> flag is also particularly useful here: if you’re working with users
who have many followers or friends, it can take some time to process them.
Verbose output will print progress information (<code class="docutils literal notranslate"><span class="pre">-v</span> <span class="pre">-v</span></code> will print even more)
to help monitor the job.</p>
<p>The fetched follow graph data itself is stored in a <a class="reference external" href="https://en.wikipedia.org/wiki/Slowly_changing_dimension#Type_2:_add_new_row">type-2 SCD</a>
format, which (without getting into the details) means that you can just keep
running these commands and storing multiple snapshots at different times,
without using enormous amounts of disk space. (See the <a class="reference internal" href="export.html"><span class="doc">exporting data
vignette</span></a> for details of how to get follow graph snapshots
out of the SCD table.)</p>
</div>
</div>
<div class="section" id="putting-it-all-together">
<h2>Putting it all together<a class="headerlink" href="#putting-it-all-together" title="Permalink to this heading"></a></h2>
<p>Here’s all of our hard work in one little script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="nb">set</span> -xe

<span class="c1"># We assume you&#39;ve already installed the twclient package (e.g., from PyPI),</span>
<span class="c1"># set up the database, and gotten API keys, so we won&#39;t show any of that</span>
<span class="c1"># here. See also the command-line -h/--help option for more info.</span>

twclient config add-db -u <span class="s2">&quot;postgresql:///&quot;</span> postgres
twclient initialize -y

twclient config add-api -n twitter1 <span class="se">\</span>
    --consumer-key XXXXX <span class="se">\</span>
    --consumer-secret XXXXXX <span class="se">\</span>
    --token XXXXXX <span class="se">\</span>
    --token-secret XXXXXX

twclient config add-api -n twitter2 <span class="se">\</span>
    --consumer-key XXXXX <span class="se">\</span>
    --consumer-secret XXXXXX <span class="se">\</span>
    --token XXXXXX <span class="se">\</span>
    --token-secret XXXXXX

tail -n +2 lists.csv <span class="p">|</span> xargs twclient fetch users -v -b -l

twclient tag create twitter_lists
tail -n +2 lists.csv <span class="p">|</span> xargs twclient tag apply twitter_lists -l

tail -n +2 users.csv <span class="p">|</span> xargs twclient fetch users -v -b -n

twclient tag create twitter_users
tail -n +2 users.csv <span class="p">|</span> xargs twclient tag apply twitter_users -l

twclient tag create universe
twclient tag apply universe -g twitter_users twitter_lists

twclient fetch tweets -v -b -g universe

twclient fetch friends -v -b -g universe
twclient fetch followers -v -b -j <span class="m">5000</span> -g universe
</pre></div>
</div>
<p>Tada! Now you have data in a DB. You can use canned SQL queries, like those in
the <a class="reference internal" href="export.html"><span class="doc">exporting data vignette</span></a>, to get whatever piece
of data you want out of it: the follow graph, a user’s tweets, mention / quote
/ reply / retweet graphs, etc. Your creativity in SQL is the limit.</p>
<p>Wasn’t that easier than you’re used to?</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../overview/license.html" class="btn btn-neutral float-left" title="License" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="export.html" class="btn btn-neutral float-right" title="Working with fetched data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019-2021, Massachusetts Institute of Technology.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>